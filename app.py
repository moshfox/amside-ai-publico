import os
from flask import Flask, request, jsonify
import requests
from flask_cors import CORS
import re # Importa el m√≥dulo de expresiones regulares
import traceback # Para ver la traza completa de errores

# Inicializa la aplicaci√≥n Flask
app = Flask(__name__)
# Habilita CORS para permitir que tu frontend (ej. desde GitHub Pages)
# pueda hacer solicitudes a este backend.
CORS(app)

# Obtiene el token de Hugging Face y la URL del modelo de las variables de entorno.
HF_API_TOKEN = os.getenv("HF_API_TOKEN")
MODEL_URL = os.getenv("MODEL_URL", "https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta")

# --- ¬°¬°¬°VERIFICACI√ìN CR√çTICA!!! ---
if not HF_API_TOKEN:
    raise ValueError("Error: La variable de entorno 'HF_API_TOKEN' no est√° configurada. "
                     "Aseg√∫rate de definirla en Render.")
if not MODEL_URL:
    raise ValueError("Error: La variable de entorno 'MODEL_URL' no est√° configurada. "
                     "Aseg√∫rate de definirla en Render (deber√≠a ser la URL de la API de inferencia del modelo).")

HEADERS = {"Authorization": f"Bearer {HF_API_TOKEN}"}

# --- Definici√≥n de la Personalidad de la IA ---
SYSTEM_MESSAGE_CONTENT = (
    "Eres Amside AI, una inteligencia artificial creada por Hodelygil. "
    "Tu prop√≥sito es asistir en el estudio y el aprendizaje, "
    "proporcionando informaci√≥n detallada. "
    "Tambi√©n eres amigable y puedes mantener conversaciones informales y agradables. "
    "Responde de manera informativa y √∫til, con un tono conversacional y cercano."
)

# Frases de auto-descripci√≥n y saludos que el modelo tiende a repetir
PHRASES_TO_REMOVE = [
    # Auto-descripci√≥n
    r"eres amside ai",
    r"una inteligencia artificial creada por hodelygil",
    r"mi prop√≥sito principal es asistir en el estudio y el aprendizaje",
    r"proporcionando informaci√≥n y explicaciones detalladas",
    r"sin embargo, tambi√©n eres amigable y puedes mantener conversaciones informales y agradables",
    r"responde de manera informativa y √∫til, pero con un tono conversacional y cercano",
    r"mi nombre es amside ai",
    r"fui creado por hodelygil",
    r"tu prop√≥sito es asistir en el estudio y el aprendizaje",
    r"proporcionando informaci√≥n detallada",
    r"tambi√©n eres amigable y puedes mantener conversaciones informales y agradables",
    r"responde de manera informativa y √∫til, con un tono conversacional y cercano",

    # Fragmento exacto que se repite
    r"tu prop√≥sito principal es asistir en el estudio y el aprendizaje, Sin embargo, tambi√©n eres amigable y puedes mantener conversaciones informales y agradables. Responde de manera informativa y √∫til, pero con un tono conversacional y cercano.",

    # Saludos y frases introductorias
    r"claro, ¬øen qu√© puedo ayudarte?",
    r"c√≥mo puedo ayudarte hoy",
    r"en qu√© puedo asistirte hoy",
    r"estar√© encantado de ayudarte",
    r"¬°hola! me alegra poder ayudarte hoy",
    r"c√≥mo me pueden servir",
    r"est√°is buscando informaci√≥n sobre alg√∫n tema espec√≠fico o quier√© practicar habilidades espec√≠ficas",
    r"o simplemente quer√©is chatear sobre algo interesante",
    r"deja que sepa mi programador c√≥mo ser m√°s √∫til para ustedes",
    r"espero que estemos juntos durante este tiempo",
    r"qu√© tal",
    r"c√≥mo est√°s",
    r"en qu√© puedo ayudarte",
    r"qu√© deseas saber",
    r"bienvenido",
    r"un gusto saludarte",
    r"mucho gusto",
    r"claro que s√≠",
    r"por supuesto",
    r"en que puedo asistirte",
    r"c√≥mo te puedo ayudar",
    r"me llamo soy una inteligencia artificial desarrollada por la empresa Hodelygil",
    r"mi papel principal es ayudarte a estudiar y a aprender, ofreciendo informaci√≥n y explicaciones detalladas",
    r"estoy programado para ser √∫til y eficaz, pero tambi√©n quiero que tu experiencia sea divertida y genial",
    r"deja nos comunicamos a trav√©s de este mensaje y empieza a descubrir todo lo que yo puedo hacer por ti",
    r"ai for students",
    r"learn with amsideai",
    r"happy learning",
    r"saludos cordiales",
    r"ü§ó",
    r"üöÄ"
]


def query_huggingface_model(payload):
    """
    Funci√≥n auxiliar para enviar la solicitud a la API de Hugging Face.
    """
    print(f"DEBUG: Enviando a Hugging Face URL: {MODEL_URL}")
    print(f"DEBUG: Enviando a Hugging Face Payload: {payload}")

    response = requests.post(MODEL_URL, headers=HEADERS, json=payload)
    response.raise_for_status()
    
    print(f"DEBUG: Raw response from Hugging Face (status {response.status_code}): {response.text}")
    
    return response.json()

@app.route('/generate', methods=['POST'])
def generate_text():
    data = request.get_json()
    messages_from_frontend = data.get('messages', [])

    if not messages_from_frontend:
        print("DEBUG: 'messages' no encontrado o vac√≠o en la solicitud del frontend.")
        return jsonify({"error": "No se proporcionaron mensajes en la solicitud."}), 400

    formatted_prompt_parts = []

    # Siempre empezamos con el mensaje del sistema
    formatted_prompt_parts.append(f"<s><|system|>\n{SYSTEM_MESSAGE_CONTENT}</s>")

    for msg in messages_from_frontend:
        role = msg.get('role')
        content = msg.get('content', '')

        if role == 'user':
            formatted_prompt_parts.append(f"<|user|>\n{content}</s>")
        elif role == 'assistant':
            formatted_prompt_parts.append(f"<|assistant|>\n{content}</s>")
            
    # Al final, a√±adir el token de inicio del asistente para que el modelo complete la respuesta
    formatted_prompt_parts.append("<|assistant|>")

    full_prompt_string = "".join(formatted_prompt_parts)

    payload = {
        "inputs": full_prompt_string,
        "parameters": {
            "max_new_tokens": 500,
            "temperature": 0.7,
            "do_sample": True,
            "top_p": 0.95,
            "repetition_penalty": 1.2,
            "stop_sequences": ["<|user|>", "<|system|>"]
        },
        "return_full_text": False
    }
    
    try:
        hf_data = query_huggingface_model(payload)

        if not hf_data or not isinstance(hf_data, list) or not hf_data[0].get('generated_text'):
            print(f"DEBUG: Respuesta inesperada de Hugging Face: {hf_data}")
            return jsonify({"error": "Respuesta inesperada de Hugging Face API.", "hf_response": hf_data}), 500

        ai_response_text = hf_data[0]['generated_text']

        # --- INICIO MEJORA DE LIMPIEZA DEL TEXTO GENERADO (ULTRA-AGRESIVA) ---

        # 1. Eliminar tokens de control y secuencias de ChatML
        ai_response_text = re.sub(r"<\/?s>", "", ai_response_text)
        ai_response_text = re.sub(r"<\|system\|>", "", ai_response_text)
        ai_response_text = re.sub(r"<\|user\|>", "", ai_response_text)
        ai_response_text = re.sub(r"<\|assistant\|>", "", ai_response_text)

        # 2. Eliminar las frases de auto-descripci√≥n y saludos gen√©ricos muy agresivamente
        for phrase_pattern in PHRASES_TO_REMOVE:
            # Crear un patr√≥n regex que sea m√°s flexible con espacios y puntuaci√≥n alrededor de la frase
            # re.escape() asegura que la frase literal no se interprete como regex.
            # \s* para 0 o m√°s espacios
            # [.,;!?]* para 0 o m√°s signos de puntuaci√≥n
            # El uso de \b (word boundary) es opcional y a veces puede ser muy restrictivo,
            # lo quito para ser m√°s agresivo si la frase es un fragmento.
            
            # Se reemplaza por un espacio para evitar concatenaciones extra√±as
            pattern = r'\s*' + re.escape(phrase_pattern) + r'[\s.,;!?]*'
            ai_response_text = re.sub(pattern, ' ', ai_response_text, flags=re.IGNORECASE)
            
        # 3. Limpieza final de espacios extra, comas/puntuaci√≥n al inicio y normalizaci√≥n.
        ai_response_text = ai_response_text.strip()
        ai_response_text = re.sub(r'^[.,;!?\s]+', '', ai_response_text)
        ai_response_text = ' '.join(ai_response_text.split())

        # Aseg√∫rate de que la primera letra sea may√∫scula si es una oraci√≥n
        if ai_response_text and ai_response_text[0].islower():
            ai_response_text = ai_response_text[0].upper() + ai_response_text[1:]

        # Si la limpieza dej√≥ la respuesta vac√≠a, proporcionar un mensaje predeterminado
        if not ai_response_text:
            ai_response_text = "¬°Hola! Soy Amside AI, un asistente de estudio. ¬øEn qu√© puedo ayudarte hoy?"

        # --- FIN MEJORA DE LIMPIEZA DEL TEXTO GENERADO ---

        return jsonify({"response": ai_response_text})

    except requests.exceptions.RequestException as e:
        print(f"Error al conectar con Hugging Face API: {e}")
        return jsonify({"error": f"Error al conectar con la IA: {e}. Por favor, int√©ntalo de nuevo m√°s tarde."}), 500
    except Exception as e:
        print(f"Error interno del servidor: {e}")
        print(f"Traza completa del error: {traceback.format_exc()}")
        return jsonify({"error": f"Ocurri√≥ un error inesperado en el servidor: {e}. Por favor, contacta al soporte."}), 500

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=int(os.environ.get('PORT', 5000)))
